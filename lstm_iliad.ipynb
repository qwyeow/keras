{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                             LSTM Language Model \n",
    " \n",
    " Let's create a language model to generate Homer's Iliad, the same manner in which Andrej Karpathy created a Paul Graham generator in his [blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). To do so, we'll use [Keras](https://keras.io/) to build a single-layer LSTM (Long-Short-Term Memory) model with 128 hidden nodes. \n",
    " \n",
    " The model will take an arbituary length of characters (60 in this case) from Iliad to learn to predict the 61st character. It will have no knowledge of any word used in Iliad, only characters. By chaining the predictions together, we can generate new Iliad text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a function to load the source text, which is downloaded from [Gutenberg](http://www.gutenberg.org/ebooks/author/705). The source is cleaned by removing the prefaces, chapter introductions, footnotes, annotations, etc, anything that is not written by Homer himself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_text(source):\n",
    "    try:\n",
    "        with open(source) as f:\n",
    "            text = f.read().lower()   \n",
    "        return text\n",
    "    except OSError as e:\n",
    "        print(\"Could not process file because of {}\".format(str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We open the source text and print a few lines to visually inspect the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of source text: 880635 sentences\n",
      "\n",
      "Source text: \n",
      "   achilles' wrath, to greece the direful spring\n",
      "  of woes unnumber'd, heavenly goddess, sing!\n",
      "  that wrath which hurl'd to pluto's gloomy reign\n",
      "  the souls of mighty chiefs untimely slain;\n",
      "  whose lim\n"
     ]
    }
   ],
   "source": [
    "file = \"./Iliad.txt\"\n",
    "text = source_text(file)   \n",
    "print('Length of source text:', len(text), 'sentences\\n')\n",
    "print('Source text:', '\\n',text[0:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    " \n",
    " \n",
    "It appears that we still need to get rid of the space (actually two spaces) in front of every new line. So let's shift every sentence to the left by 2 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "achilles' wrath, to greece the direful spring\n",
      "of woes unnumber'd, heavenly goddess, sing!\n",
      "that wrath which hurl'd to pluto's gloomy reign\n",
      "the souls of mighty chiefs untimely slain;\n",
      "whose limbs unburied on the naked shore,\n",
      "devouring dogs and hungry vultures tore.\n",
      "since great achilles and atrides stro\n"
     ]
    }
   ],
   "source": [
    "while \"  \" in text:\n",
    "    text = text.replace(\"  \", \"\")\n",
    "print(text[0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The create_input_output() function creates input sentence of arbituary length (in this case 60 characters) and pairs it with an output character (the 61st character) to be the corresponding output label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_output(text, length = 60, stepsize = 3 ):    \n",
    "    predicting_sentences = []\n",
    "    predicted_char = []    \n",
    "    for char in range(0, len(text)-length, stepsize):\n",
    "        predicting_sentences.append(text[char:char+length])\n",
    "        predicted_char.append(text[char+length])        \n",
    "    return predicting_sentences, predicted_char "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example the 5th input sentence \"to greece the direful spring of woes unnumber'd, heavenly\" has a corresponding output character \"g\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: , to greece the direful spring\n",
      "of woes unnumber'd, heavenly  \n",
      "\n",
      "Output label: g\n"
     ]
    }
   ],
   "source": [
    "predicting_sentences, predicted_char = create_input_output(text)\n",
    "print(\"Input sentence:\", predicting_sentences[5], \"\\n\")\n",
    "print(\"Output label:\", predicted_char[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two dictionaries are created, of which one of them, char_to_index(), will map each character found in the source text to an index, while the other, index_to_char(), will map an index to a character. There are a total of 31 different characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_index(text):\n",
    "    char2index = {char:i for i, char in enumerate(sorted(set(text)))}\n",
    "    return char2index \n",
    "\n",
    "def index_to_char(text):\n",
    "    index2char = {i:char for i, char in enumerate(sorted(set(text)))}\n",
    "    return index2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_to_index: {'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, ':': 10, ';': 11, '?': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'k': 23, 'l': 24, 'm': 25, 'n': 26, 'o': 27, 'p': 28, 'q': 29, 'r': 30, 's': 31, 't': 32, 'u': 33, 'v': 34, 'w': 35, 'x': 36, 'y': 37, 'z': 38, 'Ä‡': 39}\n"
     ]
    }
   ],
   "source": [
    "print(\"char_to_index:\", char_to_index(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For characters or words to be fed intp a deep learning model, the input sentences and output labels must be converted to tensors first. The function vectorize() will convert both the sentences and labels into one-hot vectors through the function vectorize()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentences, char_to_index,predicted_char,length = 60): \n",
    "    \n",
    "    input_sentence = np.zeros((len(sentences), length, len(char_to_index)))\n",
    "    output_char = np.zeros((len(sentences), len(char_to_index)))\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for j, char in enumerate(sentence):\n",
    "            input_sentence[i, j, char_to_index[char]] = 1\n",
    "            \n",
    "        output_char[i, char_to_index[predicted_char[i]]] = 1\n",
    "        \n",
    "    return input_sentence, output_char        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicting_sentences, predicted_char = create_input_output(text)\n",
    "char2index = char_to_index(text)\n",
    "index2char = index_to_char(text)\n",
    "input_sentence, output_char = vectorize(predicting_sentences, char2index, predicted_char, length = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1st sentence and its corresponding output label are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot input sentence of shape(280894, 60, 40): \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] \n",
      "\n",
      "One-hot output label of shape(280894, 40): \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"One-hot input sentence of shape{}:\".format(input_sentence.shape),\"\\n\", input_sentence[0], \"\\n\")\n",
    "print(\"One-hot output label of shape{}:\".format(output_char.shape),\"\\n\", output_char[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single-layer LSTM model with 128 hidden nodes is built using Keras. It is connected to a Dense layer which outputs a vector of 39 probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 128)               86528     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 40)                5160      \n",
      "=================================================================\n",
      "Total params: 91,688\n",
      "Trainable params: 91,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(input_sentence.shape[1], input_sentence.shape[2]))) \n",
    "model.add(keras.layers.Dense(input_sentence.shape[2], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained for 60 epochs, which saw its cross-entropy loss declined from 2.2934 to 1.1536. Thereafter the entire model architecture and its weights are saved using model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(input_sentence, output_char, batch_size=128, epochs=60)\n",
    "model.save(\"iliad_lstm_128_1layer_trained-at-60epoch.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/60 \n",
    " \n",
    " \n",
    "280894/280894 [==============================] - 155s 551us/step - loss: 2.2934 \n",
    " \n",
    "Epoch 59/60 \n",
    " \n",
    "280894/280894 [==============================] - 151s 538us/step - loss: 1.1574 \n",
    "\n",
    "\n",
    "Epoch 60/60 \n",
    " \n",
    "280894/280894 [==============================] - 150s 534us/step - loss: 1.1536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can be reloaded again anytime now that it has been saved by calling load_model() and compiling the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./iliad lstm 128 60th epoch/iliad_lstm_128_1layer_trained-at-60epoch.h5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function renormalization() can be used to renomalize the predicted probabilities. The higher the temperature, the more creative the generated text will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalization(old_probabilities, temperature):    \n",
    "    prob = np.log(old_probabilities)/temperature  \n",
    "    new_probabilities = np.exp(prob)   \n",
    "    return new_probabilities / np.sum(new_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the renormalized probabilities, the function sample() will return the prediction, which is the character, out of a total of 40 characters, with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = renormalization(preds, temperature) \n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we generate a seed sentence of length 60, and use this seed to generate new Iliad text of 500 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "start_index = random.randint(0, len(text) - input_sentence.shape[1] - 1)\n",
    "generated_text = text[start_index: start_index + input_sentence.shape[1]]\n",
    "print('Generating with seed: \"' + generated_text + '\"' + \"\\n\")\n",
    "\n",
    "print(generated_text, end = \"\")\n",
    "\n",
    "for i in range(500):\n",
    "    sampled = np.zeros((1, input_sentence.shape[1], input_sentence.shape[2]))\n",
    "    \n",
    "    for t, char in enumerate(generated_text):\n",
    "        sampled[0, t, char2index[char]] = 1.\n",
    "        \n",
    "    preds = model.predict(sampled, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature=0.5)\n",
    "    next_char = index2char[next_index]\n",
    "    generated_text += next_char\n",
    "    generated_text = generated_text[1:]\n",
    "    sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example at temperature 1.0:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating with seed: \"ean, owns my reign.  \n",
    "  and his hush'd waves lie silent on the\"  \n",
    "  \n",
    "  \n",
    "  \n",
    "ean, owns my reign.  \n",
    "  and his hush'd waves lie silent on the glore,  \n",
    "and art: he fronm'd a heaving brave depier,  \n",
    "our all her anger natred band to greet.  \n",
    "with thy distribis with the mournful sway  \n",
    "far ounded in earth a the dispants undies.  \n",
    "as still'd atoltm him with re dass'd.\"    \n",
    "\n",
    "moont, and some arior of my manly of the plains,  \n",
    "and pale our gloomy vengeances shall we stand,  \n",
    "through all before their chalarj blow the way.  \n",
    "with hersed fame the hunget in alreaty alm,  \n",
    "demand the triphy and a groy he fall.  \n",
    "but sopelive whom in ample gims ipplaced  \n",
    "the fields the wo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example at temperature 1.0:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating with seed: \"o shall thy pity and forbearance give  \n",
    "  a weak old man to se\"  \n",
    "\n",
    "o shall thy pity and forbearance give  \n",
    "  a weak old man to searcy morena; day.  \n",
    "what yet our close but fatient seen of heaven,  \n",
    "thus savight heavens, and glowine when rage rend,  \n",
    "to twose the skies gifts, and heaven to will;  \n",
    "and morcay so ?ige, leave fate and maid:  \n",
    "mournful, atsin the trojans mourn'd bendate;  \n",
    "arm from silent our rage and sacred keep.\"    \n",
    "\n",
    "tid heaven recrioms but it not that hail!  \n",
    "beholl; my emphy heeds, me, listence mend,  \n",
    "sumpuse achilles they vingim; appear,  \n",
    "nor eye his flamious inoved and round,  \n",
    "let not and troy not persuas for his sire,  \n",
    "ampl  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example at temperature 1.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating with seed: \"e this menace, this insulting strain?  \n",
    "  enormous boaster! do\"    \n",
    "\n",
    "e this menace, this insulting strain?  \n",
    "  enormous boaster! doyrned had epach;  \n",
    "their some desagg hear, from his day we spear:  \n",
    "the vigour ob, the tanks of nep herce weigs  \n",
    "confess'd the chief the flying braves of are,  \n",
    "and thus he moves his daysing brother shared.  \n",
    "that to he spoke, and send\" the king of night,  \n",
    "in yir the fields in arm'd his body train,  \n",
    "gorove arms, whoms troy! forbids the vangat of bown.  \n",
    "s\"o favour townom reens, the assiust of he shall,  \n",
    "and nation's vengeand, or his shule defear.  \n",
    "dither'd the roughting, phoebus in edert  \n",
    "and view his phrygian   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Less creative sentence at temperature of 0.5, but higher fidelity:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating with seed: \"inguish'd o'er the field  \n",
    "  by the broad glittering of the se\"    \n",
    "\n",
    "inguish'd o'er the field  \n",
    "  by the broad glittering of the seats of war.  \n",
    "but seat the last the field resounding shore,  \n",
    "the whom the victim the deep they bower:  \n",
    "the son of the mannated the deed of lence.  \n",
    "so such of men the fame of man a spire,  \n",
    "the shore the thunder long strong shorted plain.  \n",
    "so the shall pierced his fate the power of heaven,  \n",
    "their sheathe the heaven their stern deffarior crown'd,  \n",
    "and stand defengeant on the short of fate.  \n",
    "now with a seer shall same the lord of sight,  \n",
    "the darkness from his arm shall tream of heaven.  \n",
    "whom might they falt, an  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another at temperature of 0.5:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating with seed: \"his tent the chief retains,  \n",
    "  safe to transport him to his n\"    \n",
    "\n",
    "his tent the chief retains,  \n",
    "  safe to transport him to his nigh bore.  \n",
    "so braves forbeas the trojan force in vain,  \n",
    "with joy some son of jove a sons of fame:  \n",
    "nor to his arms, and lear the trojan fields,  \n",
    "to sumble steel, and glorious of the diren:  \n",
    "the phoans of the darents of the skies,  \n",
    "but the wall one imparion ranks the shore,  \n",
    "the victor passing to the furion son:  \n",
    "so springly war, and breathes in the fought,  \n",
    "and the rise start the short of closed of the die.    \n",
    "\n",
    "so said, and short, the fields of man contends;  \n",
    "and all the grecian thrones spreads the grecians   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:  \n",
    "  \n",
    "1) Deep Learning with Python - Francois Chollet   \n",
    "2) Deep Learning with Keras - Antonio Gulli, Sujit Pal   \n",
    "3)  [The Unreasonable Effectiveness of Recurrent Neural Networks - Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
